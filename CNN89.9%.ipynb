{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "Epoch 1/50\n",
      "184/184 [==============================] - 30s 161ms/step - loss: 3.9520 - accuracy: 0.0486 - val_loss: 3.3106 - val_accuracy: 0.0875\n",
      "Epoch 2/50\n",
      "184/184 [==============================] - 28s 152ms/step - loss: 2.5607 - accuracy: 0.2740 - val_loss: 1.8044 - val_accuracy: 0.4750\n",
      "Epoch 3/50\n",
      "184/184 [==============================] - 29s 158ms/step - loss: 1.7098 - accuracy: 0.4722 - val_loss: 1.2233 - val_accuracy: 0.7125\n",
      "Epoch 4/50\n",
      "184/184 [==============================] - 28s 150ms/step - loss: 1.2943 - accuracy: 0.5893 - val_loss: 0.6334 - val_accuracy: 0.8125\n",
      "Epoch 5/50\n",
      "184/184 [==============================] - 29s 156ms/step - loss: 1.0158 - accuracy: 0.6743 - val_loss: 0.5595 - val_accuracy: 0.8250\n",
      "Epoch 6/50\n",
      "184/184 [==============================] - 27s 144ms/step - loss: 0.8791 - accuracy: 0.7105 - val_loss: 0.5863 - val_accuracy: 0.8250\n",
      "Epoch 7/50\n",
      "184/184 [==============================] - 26s 140ms/step - loss: 0.7602 - accuracy: 0.7513 - val_loss: 0.4725 - val_accuracy: 0.8375\n",
      "Epoch 8/50\n",
      "184/184 [==============================] - 26s 139ms/step - loss: 0.6736 - accuracy: 0.7732 - val_loss: 0.4492 - val_accuracy: 0.8250\n",
      "Epoch 9/50\n",
      "184/184 [==============================] - 26s 139ms/step - loss: 0.6253 - accuracy: 0.7933 - val_loss: 0.4838 - val_accuracy: 0.8500\n",
      "Epoch 10/50\n",
      "184/184 [==============================] - 26s 140ms/step - loss: 0.5453 - accuracy: 0.8207 - val_loss: 0.2671 - val_accuracy: 0.8750\n",
      "Epoch 11/50\n",
      "184/184 [==============================] - 27s 149ms/step - loss: 0.5209 - accuracy: 0.8260 - val_loss: 0.3205 - val_accuracy: 0.8875\n",
      "Epoch 12/50\n",
      "184/184 [==============================] - 27s 148ms/step - loss: 0.4945 - accuracy: 0.8356 - val_loss: 0.2022 - val_accuracy: 0.9375\n",
      "Epoch 13/50\n",
      "184/184 [==============================] - 27s 147ms/step - loss: 0.4639 - accuracy: 0.8450 - val_loss: 0.3978 - val_accuracy: 0.8375\n",
      "Epoch 14/50\n",
      "184/184 [==============================] - 30s 164ms/step - loss: 0.4329 - accuracy: 0.8535 - val_loss: 0.3494 - val_accuracy: 0.8625\n",
      "Epoch 15/50\n",
      "184/184 [==============================] - 28s 150ms/step - loss: 0.3987 - accuracy: 0.8629 - val_loss: 0.1391 - val_accuracy: 0.9500\n",
      "Epoch 16/50\n",
      "184/184 [==============================] - 29s 160ms/step - loss: 0.3784 - accuracy: 0.8717 - val_loss: 0.2509 - val_accuracy: 0.8750\n",
      "Epoch 17/50\n",
      "184/184 [==============================] - 30s 160ms/step - loss: 0.3420 - accuracy: 0.8839 - val_loss: 0.2849 - val_accuracy: 0.8750\n",
      "Epoch 18/50\n",
      "184/184 [==============================] - 29s 156ms/step - loss: 0.3370 - accuracy: 0.8809 - val_loss: 0.2099 - val_accuracy: 0.9125\n",
      "Epoch 19/50\n",
      "184/184 [==============================] - 29s 157ms/step - loss: 0.3301 - accuracy: 0.8857 - val_loss: 0.3005 - val_accuracy: 0.8625\n",
      "Epoch 20/50\n",
      "184/184 [==============================] - 26s 144ms/step - loss: 0.2965 - accuracy: 0.8962 - val_loss: 0.1749 - val_accuracy: 0.9125\n",
      "Epoch 21/50\n",
      "184/184 [==============================] - 27s 148ms/step - loss: 0.2889 - accuracy: 0.9000 - val_loss: 0.1659 - val_accuracy: 0.9375\n",
      "Epoch 22/50\n",
      "184/184 [==============================] - 27s 144ms/step - loss: 0.3007 - accuracy: 0.8943 - val_loss: 0.3072 - val_accuracy: 0.8500\n",
      "Epoch 23/50\n",
      "184/184 [==============================] - 27s 146ms/step - loss: 0.2660 - accuracy: 0.9080 - val_loss: 0.1791 - val_accuracy: 0.9375\n",
      "Epoch 24/50\n",
      "184/184 [==============================] - 26s 144ms/step - loss: 0.2558 - accuracy: 0.9125 - val_loss: 0.2054 - val_accuracy: 0.9250\n",
      "Epoch 25/50\n",
      "184/184 [==============================] - 29s 156ms/step - loss: 0.2379 - accuracy: 0.9170 - val_loss: 0.4573 - val_accuracy: 0.7875\n",
      "Epoch 26/50\n",
      "184/184 [==============================] - 27s 146ms/step - loss: 0.2508 - accuracy: 0.9122 - val_loss: 0.3933 - val_accuracy: 0.8500\n",
      "Epoch 27/50\n",
      "184/184 [==============================] - 26s 143ms/step - loss: 0.2241 - accuracy: 0.9211 - val_loss: 0.2137 - val_accuracy: 0.9250\n",
      "Epoch 28/50\n",
      "184/184 [==============================] - 28s 153ms/step - loss: 0.2261 - accuracy: 0.9213 - val_loss: 0.5197 - val_accuracy: 0.8500\n",
      "Epoch 29/50\n",
      "184/184 [==============================] - 27s 148ms/step - loss: 0.2184 - accuracy: 0.9231 - val_loss: 0.3972 - val_accuracy: 0.8750\n",
      "Epoch 30/50\n",
      "184/184 [==============================] - 25s 138ms/step - loss: 0.2142 - accuracy: 0.9226 - val_loss: 0.3049 - val_accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "184/184 [==============================] - 27s 147ms/step - loss: 0.1993 - accuracy: 0.9303 - val_loss: 0.0799 - val_accuracy: 0.9625\n",
      "Epoch 32/50\n",
      "184/184 [==============================] - 27s 146ms/step - loss: 0.1946 - accuracy: 0.9325 - val_loss: 0.2314 - val_accuracy: 0.9125\n",
      "Epoch 33/50\n",
      "184/184 [==============================] - 28s 151ms/step - loss: 0.1906 - accuracy: 0.9329 - val_loss: 0.2350 - val_accuracy: 0.9375\n",
      "Epoch 34/50\n",
      "184/184 [==============================] - 27s 149ms/step - loss: 0.1884 - accuracy: 0.9353 - val_loss: 0.1171 - val_accuracy: 0.9250\n",
      "Epoch 35/50\n",
      "184/184 [==============================] - 27s 148ms/step - loss: 0.1735 - accuracy: 0.9367 - val_loss: 0.3554 - val_accuracy: 0.9000\n",
      "Epoch 36/50\n",
      "184/184 [==============================] - 27s 144ms/step - loss: 0.1851 - accuracy: 0.9330 - val_loss: 0.1869 - val_accuracy: 0.9250\n",
      "Epoch 37/50\n",
      "184/184 [==============================] - 27s 147ms/step - loss: 0.1840 - accuracy: 0.9379 - val_loss: 0.1347 - val_accuracy: 0.9375\n",
      "Epoch 38/50\n",
      "184/184 [==============================] - 28s 150ms/step - loss: 0.1506 - accuracy: 0.9476 - val_loss: 0.4122 - val_accuracy: 0.9000\n",
      "Epoch 39/50\n",
      "184/184 [==============================] - 27s 147ms/step - loss: 0.1690 - accuracy: 0.9412 - val_loss: 0.1747 - val_accuracy: 0.9375\n",
      "Epoch 40/50\n",
      "184/184 [==============================] - 29s 156ms/step - loss: 0.1476 - accuracy: 0.9471 - val_loss: 0.2525 - val_accuracy: 0.9125\n",
      "Epoch 41/50\n",
      "184/184 [==============================] - 28s 150ms/step - loss: 0.1533 - accuracy: 0.9458 - val_loss: 0.3633 - val_accuracy: 0.9125\n",
      "Epoch 42/50\n",
      "184/184 [==============================] - 27s 147ms/step - loss: 0.1524 - accuracy: 0.9472 - val_loss: 0.4426 - val_accuracy: 0.8625\n",
      "Epoch 43/50\n",
      "184/184 [==============================] - 28s 152ms/step - loss: 0.1443 - accuracy: 0.9503 - val_loss: 0.5723 - val_accuracy: 0.9125\n",
      "Epoch 44/50\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.1428 - accuracy: 0.9514 - val_loss: 0.2953 - val_accuracy: 0.8750\n",
      "Epoch 45/50\n",
      "184/184 [==============================] - 27s 144ms/step - loss: 0.1294 - accuracy: 0.9558 - val_loss: 0.1700 - val_accuracy: 0.9375\n",
      "Epoch 46/50\n",
      "184/184 [==============================] - 26s 141ms/step - loss: 0.1499 - accuracy: 0.9506 - val_loss: 0.4829 - val_accuracy: 0.9000\n",
      "Epoch 47/50\n",
      "184/184 [==============================] - 25s 135ms/step - loss: 0.1345 - accuracy: 0.9534 - val_loss: 0.6053 - val_accuracy: 0.8750\n",
      "Epoch 48/50\n",
      "184/184 [==============================] - 26s 141ms/step - loss: 0.1345 - accuracy: 0.9524 - val_loss: 0.3888 - val_accuracy: 0.8625\n",
      "Epoch 49/50\n",
      "184/184 [==============================] - 25s 137ms/step - loss: 0.1322 - accuracy: 0.9529 - val_loss: 0.4395 - val_accuracy: 0.8625\n",
      "Epoch 50/50\n",
      "184/184 [==============================] - 25s 135ms/step - loss: 0.1208 - accuracy: 0.9601 - val_loss: 0.3025 - val_accuracy: 0.9000\n",
      "Test loss: 0.30254584550857544\n",
      "Test accuracy: 89.99999761581421\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Visualisation imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Scikit learn for preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Keras Imports - CNN\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# load data(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "read=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/trainset28.csv\").values\n",
    "arr=np.array\n",
    "arr = read.reshape(18367,28,28,1)\n",
    "x_train=arr\n",
    "readt=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/testset28.csv\").values\n",
    "arrt=np.array\n",
    "arrt = readt.reshape(80,28,28,1)\n",
    "x_test=arrt\n",
    "y_train=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/training_label28.csv\").values\n",
    "y_test=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/Test_label.csv\").values\n",
    "\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "im_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train=x_train\n",
    "X_test=x_test\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)\n",
    "# define the larger model\n",
    "def modelv2():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(28,28,1), activation='relu'))\n",
    "    model.add(Conv2D(32,(3,3),strides=(1,1),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32,(3,3),strides=(1,1),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3,3),strides=(1,1),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32,(3,3),strides=(1,1),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3,3),strides=(1,1),padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=modelv2()\n",
    "history = model.fit(X_train, y_train,batch_size=100, epochs=50,validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"C:/Users/helid/PycharmProjects/GujOCR/model/CNN89.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 6, 6, 32)          18464     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 66)                8514      \n",
      "=================================================================\n",
      "Total params: 123,938\n",
      "Trainable params: 123,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('C:/Users/helid/PycharmProjects/GujOCR/model/CNN89.h5')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted character is:ગ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict = {'ં': 0, 'ઃ': 1, 'અ': 2, 'અં': 3, 'અઃ': 4, 'આ': 5, 'ઇ': 6,\n",
    "              'ઈ': 7, 'ઉ': 8, 'ઊ': 9, 'એ': 10, 'ઐ': 11, 'ઔ': 12, 'ક': 13,\n",
    "              'ક્ષ': 14, 'ખ': 15, 'ગ': 16, 'ઘ': 17, 'ચ': 18, 'છ': 19, 'જ': 20,\n",
    "              'જ્ઞ': 21, 'ઝ': 22, 'ટ': 23, 'ઠ': 24, 'ડ': 25, 'ઢ': 26, 'ણ': 27,\n",
    "              'ત': 28, 'થ': 29, 'દ': 30, 'ધ': 31, 'ન': 32, 'પ': 33, 'ફ': 34,\n",
    "              'બ': 35, 'ભ': 36, 'મ': 37, 'ય': 38, 'ર': 39, 'લ': 40, 'ળ': 41,\n",
    "              'વ': 42, 'શ': 43, 'ષ': 44, 'સ': 45, 'હ': 46, 'ા': 47, 'િ': 48,\n",
    "              'ી': 49, 'ુ': 50, 'ૂ': 51, 'ે': 52, 'ૈ': 53, 'ો': 54, 'ૌ': 55,\n",
    "              '૦': 56, '૧': 57, '૨': 58, '૩': 59, '૪': 60, '૫': 61, '૬': 62,\n",
    "              '૭': 63, '૮': 64, '૯': 65}\n",
    "key_list = list(dict.keys()) \n",
    "val_list = list(dict.values()) \n",
    "example = x_test[29]\n",
    "prediction = model.predict(example.reshape(1,28,28, 1))\n",
    "print(prediction)\n",
    "hard_maxed_prediction = np.zeros(prediction.shape)\n",
    "hard_maxed_prediction[0][np.argmax(prediction)] = 1\n",
    "#print (hard_maxed_prediction)\n",
    "\n",
    "plt.imshow(example.reshape(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "a = int(np.argmax(prediction))\n",
    "print('Predicted character is:'+ list(dict.keys())[list(dict.values()).index(a)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (12524, 28, 28, 1)\n",
      "12524 train samples\n",
      "9 test samples\n",
      "12524/12524 [==============================] - 312s 25ms/step - loss: 4.1854 - accuracy: 0.0184 - val_loss: 4.1496 - val_accuracy: 0.0000e+00\n",
      "Test loss: 4.149569511413574\n",
      "Test accuracy: 0.0\n",
      "[[0.01595549 0.01523127 0.01525094 0.01613153 0.01613212 0.01320281\n",
      "  0.01384133 0.01376118 0.01539687 0.01470094 0.01640283 0.01602468\n",
      "  0.01400919 0.01425534 0.01486073 0.01315337 0.01514671 0.01475437\n",
      "  0.01317224 0.01428421 0.01385427 0.01207507 0.01793253 0.01822751\n",
      "  0.01451979 0.01642407 0.01365521 0.01538667 0.01833243 0.01397812\n",
      "  0.0123922  0.0116047  0.01427388 0.01456231 0.01299425 0.014315\n",
      "  0.01566225 0.01607101 0.01638268 0.01542813 0.01714048 0.01461587\n",
      "  0.0149103  0.01460673 0.0192984  0.01638072 0.01789761 0.01630821\n",
      "  0.01687065 0.01570174 0.01196082 0.0158071  0.01491509 0.01335074\n",
      "  0.01404892 0.01403342 0.0134343  0.01537013 0.01271745 0.01603286\n",
      "  0.01490469 0.01510818 0.01659461 0.01704372 0.01806898 0.01913804]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "44",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1e1c5988a16c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted character is:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 44"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 1\n",
    "num_classes = 66  #66 characters\n",
    "epochs = 1\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28,28\n",
    "read=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/train.csv\").values\n",
    "arr=np.array\n",
    "arr = read.reshape(12524,28,28,1)\n",
    "x_train=arr\n",
    "readt=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/Test.csv\").values\n",
    "arrt=np.array\n",
    "arrt = readt.reshape(9,28,28,1)\n",
    "x_test=arrt\n",
    "y_train=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/training_label.csv\").values\n",
    "y_test=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/Test_label.csv\").values\n",
    "# the data, split between train and test sets\n",
    "\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes,dtype = \"float32\")\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes,dtype = \"float32\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "dictionary = {'ં': 0, 'ઃ': 1, 'અ': 2, 'અં': 3, 'અઃ': 4, 'આ': 5, 'ઇ': 6,\n",
    "              'ઈ': 7, 'ઉ': 8, 'ઊ': 9, 'એ': 10, 'ઐ': 11, 'ઔ': 12, 'ક': 13,\n",
    "              'ક્ષ': 14, 'ખ': 15, 'ગ': 16, 'ઘ': 17, 'ચ': 18, 'છ': 19, 'જ': 20,\n",
    "              'જ્ઞ': 21, 'ઝ': 22, 'ટ': 23, 'ઠ': 24, 'ડ': 25, 'ઢ': 26, 'ણ': 27,\n",
    "              'ત': 28, 'થ': 29, 'દ': 30, 'ધ': 31, 'ન': 32, 'પ': 33, 'ફ': 34,\n",
    "              'બ': 35, 'ભ': 36, 'મ': 37, 'ય': 38, 'ર': 39, 'લ': 40, 'ળ': 41,\n",
    "              'વ': 42, 'શ': 43, 'ષ': 44, 'સ': 45, 'હ': 46, 'ા': 47, 'િ': 48,\n",
    "              'ી': 49, 'ુ': 50, 'ૂ': 51, 'ે': 52, 'ૈ': 53, 'ો': 54, 'ૌ': 55,\n",
    "              '૦': 56, '૧': 57, '૨': 58, '૩': 59, '૪': 60, '૫': 61, '૬': 62,\n",
    "              '૭': 63, '૮': 64, '૯': 65}\n",
    "\n",
    "example = x_test[1]\n",
    "prediction = model.predict(example.reshape(1,28,28, 1))\n",
    "print(prediction)\n",
    "hard_maxed_prediction = np.zeros(prediction.shape)\n",
    "hard_maxed_prediction[0][np.argmax(prediction)] = 1\n",
    "#print (hard_maxed_prediction)\n",
    "\n",
    "plt.imshow(example.reshape(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print('Predicted character is:',dictionary[np.argmax(prediction)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = x_test[89]\n",
    "prediction = model.predict(example.reshape(1,28,28, 1))\n",
    "print(prediction)\n",
    "hard_maxed_prediction = np.zeros(prediction.shape)\n",
    "hard_maxed_prediction[0][np.argmax(prediction)] = 1\n",
    "#print (hard_maxed_prediction)\n",
    "\n",
    "plt.imshow(example.reshape(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print('Predicted character is:',dictionary[np.argmax(prediction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 4.1783 - accuracy: 0.0199 - val_loss: 4.2737 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 3.9861 - accuracy: 0.0517 - val_loss: 3.7997 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 3.4274 - accuracy: 0.1282 - val_loss: 3.0575 - val_accuracy: 0.2222\n",
      "Epoch 4/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 3.0653 - accuracy: 0.1963 - val_loss: 2.7243 - val_accuracy: 0.2222\n",
      "Epoch 5/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 2.7691 - accuracy: 0.2538 - val_loss: 2.5863 - val_accuracy: 0.3333\n",
      "Epoch 6/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 2.5358 - accuracy: 0.3013 - val_loss: 2.5900 - val_accuracy: 0.2222\n",
      "Epoch 7/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 2.3304 - accuracy: 0.3513 - val_loss: 2.0305 - val_accuracy: 0.3333\n",
      "Epoch 8/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 2.1418 - accuracy: 0.3968 - val_loss: 1.7438 - val_accuracy: 0.4444\n",
      "Epoch 9/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.9840 - accuracy: 0.4361 - val_loss: 1.6066 - val_accuracy: 0.4444\n",
      "Epoch 10/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 1.8581 - accuracy: 0.4693 - val_loss: 1.3569 - val_accuracy: 0.5556\n",
      "Epoch 11/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 1.7221 - accuracy: 0.5067 - val_loss: 0.9748 - val_accuracy: 0.5556\n",
      "Epoch 12/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.6392 - accuracy: 0.5296 - val_loss: 1.3901 - val_accuracy: 0.4444\n",
      "Epoch 13/40\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 1.5387 - accuracy: 0.5553 - val_loss: 1.2862 - val_accuracy: 0.3333\n",
      "Epoch 14/40\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 1.4547 - accuracy: 0.5796 - val_loss: 1.0306 - val_accuracy: 0.6667\n",
      "Epoch 15/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 1.3848 - accuracy: 0.5969 - val_loss: 1.0591 - val_accuracy: 0.6667\n",
      "Epoch 16/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 1.3048 - accuracy: 0.6122 - val_loss: 1.0312 - val_accuracy: 0.5556\n",
      "Epoch 17/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 1.2436 - accuracy: 0.6361 - val_loss: 0.7482 - val_accuracy: 0.8889\n",
      "Epoch 18/40\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 1.1781 - accuracy: 0.6512 - val_loss: 0.9810 - val_accuracy: 0.5556\n",
      "Epoch 19/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 1.1330 - accuracy: 0.6650 - val_loss: 0.7988 - val_accuracy: 0.7778\n",
      "Epoch 20/40\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 1.0802 - accuracy: 0.6773 - val_loss: 0.7190 - val_accuracy: 0.7778\n",
      "Epoch 21/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.0406 - accuracy: 0.6862 - val_loss: 1.0077 - val_accuracy: 0.5556\n",
      "Epoch 22/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.0144 - accuracy: 0.7002 - val_loss: 0.7713 - val_accuracy: 0.7778\n",
      "Epoch 23/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.9733 - accuracy: 0.7079 - val_loss: 0.9304 - val_accuracy: 0.7778\n",
      "Epoch 24/40\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 0.9520 - accuracy: 0.7118 - val_loss: 0.7363 - val_accuracy: 0.7778\n",
      "Epoch 25/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 0.9185 - accuracy: 0.7245 - val_loss: 0.8826 - val_accuracy: 0.7778\n",
      "Epoch 26/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.8929 - accuracy: 0.7277 - val_loss: 0.7509 - val_accuracy: 0.6667\n",
      "Epoch 27/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.8543 - accuracy: 0.7403 - val_loss: 0.3534 - val_accuracy: 0.8889\n",
      "Epoch 28/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.8260 - accuracy: 0.7522 - val_loss: 0.7247 - val_accuracy: 0.7778\n",
      "Epoch 29/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8024 - accuracy: 0.7563 - val_loss: 0.8177 - val_accuracy: 0.7778\n",
      "Epoch 30/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.7873 - accuracy: 0.7650 - val_loss: 0.7036 - val_accuracy: 0.8889\n",
      "Epoch 31/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.7820 - accuracy: 0.7620 - val_loss: 0.5587 - val_accuracy: 0.8889\n",
      "Epoch 32/40\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 0.7582 - accuracy: 0.7675 - val_loss: 0.4869 - val_accuracy: 0.8889\n",
      "Epoch 33/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.7257 - accuracy: 0.7755 - val_loss: 0.5474 - val_accuracy: 0.7778\n",
      "Epoch 34/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.7013 - accuracy: 0.7845 - val_loss: 0.5437 - val_accuracy: 0.7778\n",
      "Epoch 35/40\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.6944 - accuracy: 0.7843 - val_loss: 0.4968 - val_accuracy: 0.7778\n",
      "Epoch 36/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.6799 - accuracy: 0.7909 - val_loss: 0.5004 - val_accuracy: 0.7778\n",
      "Epoch 37/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.6512 - accuracy: 0.7963 - val_loss: 0.6532 - val_accuracy: 0.5556\n",
      "Epoch 38/40\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.6358 - accuracy: 0.8049 - val_loss: 0.3828 - val_accuracy: 0.8889\n",
      "Epoch 39/40\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.6216 - accuracy: 0.8050 - val_loss: 0.3706 - val_accuracy: 0.8889\n",
      "Epoch 40/40\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.5911 - accuracy: 0.8156 - val_loss: 0.3941 - val_accuracy: 0.7778\n",
      "Test loss: 85.40829467773438\n",
      "Test accuracy: 88.88888955116272\n",
      "Large CNN Error: 22.22%\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "# load data(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "read=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/train.csv\").values\n",
    "arr=np.array\n",
    "arr = read.reshape(12524,28,28,1)\n",
    "x_train=arr\n",
    "readt=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/Test.csv\").values\n",
    "arrt=np.array\n",
    "arrt = readt.reshape(9,28,28,1)\n",
    "x_test=arrt\n",
    "y_train=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/training_label.csv\").values\n",
    "y_test=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/Test_label.csv\").values\n",
    "# the data, split between train and test sets\n",
    "\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train=x_train\n",
    "X_test=x_test\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define the larger model\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=150)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"C:/Users/helid/PycharmProjects/GujOCR/model/CNN88.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 30)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 15)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               48128     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 66)                3366      \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('C:/Users/helid/PycharmProjects/GujOCR/model/CNN88.h5')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted character is:૮\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict = {'ં': 0, 'ઃ': 1, 'અ': 2, 'અં': 3, 'અઃ': 4, 'આ': 5, 'ઇ': 6,\n",
    "              'ઈ': 7, 'ઉ': 8, 'ઊ': 9, 'એ': 10, 'ઐ': 11, 'ઔ': 12, 'ક': 13,\n",
    "              'ક્ષ': 14, 'ખ': 15, 'ગ': 16, 'ઘ': 17, 'ચ': 18, 'છ': 19, 'જ': 20,\n",
    "              'જ્ઞ': 21, 'ઝ': 22, 'ટ': 23, 'ઠ': 24, 'ડ': 25, 'ઢ': 26, 'ણ': 27,\n",
    "              'ત': 28, 'થ': 29, 'દ': 30, 'ધ': 31, 'ન': 32, 'પ': 33, 'ફ': 34,\n",
    "              'બ': 35, 'ભ': 36, 'મ': 37, 'ય': 38, 'ર': 39, 'લ': 40, 'ળ': 41,\n",
    "              'વ': 42, 'શ': 43, 'ષ': 44, 'સ': 45, 'હ': 46, 'ા': 47, 'િ': 48,\n",
    "              'ી': 49, 'ુ': 50, 'ૂ': 51, 'ે': 52, 'ૈ': 53, 'ો': 54, 'ૌ': 55,\n",
    "              '૦': 56, '૧': 57, '૨': 58, '૩': 59, '૪': 60, '૫': 61, '૬': 62,\n",
    "              '૭': 63, '૮': 64, '૯': 65}\n",
    "key_list = list(dict.keys()) \n",
    "val_list = list(dict.values()) \n",
    "example = x_test[7]\n",
    "prediction = model.predict(example.reshape(1,28,28, 1))\n",
    "print(prediction)\n",
    "hard_maxed_prediction = np.zeros(prediction.shape)\n",
    "hard_maxed_prediction[0][np.argmax(prediction)] = 1\n",
    "#print (hard_maxed_prediction)\n",
    "\n",
    "plt.imshow(example.reshape(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "a = int(np.argmax(prediction))\n",
    "print('Predicted character is:'+ list(dict.keys())[list(dict.values()).index(a)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

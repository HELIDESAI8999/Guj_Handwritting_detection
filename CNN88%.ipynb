{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 4.1783 - accuracy: 0.0199 - val_loss: 4.2737 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 3.9861 - accuracy: 0.0517 - val_loss: 3.7997 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 3.4274 - accuracy: 0.1282 - val_loss: 3.0575 - val_accuracy: 0.2222\n",
      "Epoch 4/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 3.0653 - accuracy: 0.1963 - val_loss: 2.7243 - val_accuracy: 0.2222\n",
      "Epoch 5/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 2.7691 - accuracy: 0.2538 - val_loss: 2.5863 - val_accuracy: 0.3333\n",
      "Epoch 6/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 2.5358 - accuracy: 0.3013 - val_loss: 2.5900 - val_accuracy: 0.2222\n",
      "Epoch 7/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 2.3304 - accuracy: 0.3513 - val_loss: 2.0305 - val_accuracy: 0.3333\n",
      "Epoch 8/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 2.1418 - accuracy: 0.3968 - val_loss: 1.7438 - val_accuracy: 0.4444\n",
      "Epoch 9/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.9840 - accuracy: 0.4361 - val_loss: 1.6066 - val_accuracy: 0.4444\n",
      "Epoch 10/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 1.8581 - accuracy: 0.4693 - val_loss: 1.3569 - val_accuracy: 0.5556\n",
      "Epoch 11/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 1.7221 - accuracy: 0.5067 - val_loss: 0.9748 - val_accuracy: 0.5556\n",
      "Epoch 12/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.6392 - accuracy: 0.5296 - val_loss: 1.3901 - val_accuracy: 0.4444\n",
      "Epoch 13/40\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 1.5387 - accuracy: 0.5553 - val_loss: 1.2862 - val_accuracy: 0.3333\n",
      "Epoch 14/40\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 1.4547 - accuracy: 0.5796 - val_loss: 1.0306 - val_accuracy: 0.6667\n",
      "Epoch 15/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 1.3848 - accuracy: 0.5969 - val_loss: 1.0591 - val_accuracy: 0.6667\n",
      "Epoch 16/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 1.3048 - accuracy: 0.6122 - val_loss: 1.0312 - val_accuracy: 0.5556\n",
      "Epoch 17/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 1.2436 - accuracy: 0.6361 - val_loss: 0.7482 - val_accuracy: 0.8889\n",
      "Epoch 18/40\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 1.1781 - accuracy: 0.6512 - val_loss: 0.9810 - val_accuracy: 0.5556\n",
      "Epoch 19/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 1.1330 - accuracy: 0.6650 - val_loss: 0.7988 - val_accuracy: 0.7778\n",
      "Epoch 20/40\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 1.0802 - accuracy: 0.6773 - val_loss: 0.7190 - val_accuracy: 0.7778\n",
      "Epoch 21/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.0406 - accuracy: 0.6862 - val_loss: 1.0077 - val_accuracy: 0.5556\n",
      "Epoch 22/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1.0144 - accuracy: 0.7002 - val_loss: 0.7713 - val_accuracy: 0.7778\n",
      "Epoch 23/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.9733 - accuracy: 0.7079 - val_loss: 0.9304 - val_accuracy: 0.7778\n",
      "Epoch 24/40\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 0.9520 - accuracy: 0.7118 - val_loss: 0.7363 - val_accuracy: 0.7778\n",
      "Epoch 25/40\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 0.9185 - accuracy: 0.7245 - val_loss: 0.8826 - val_accuracy: 0.7778\n",
      "Epoch 26/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.8929 - accuracy: 0.7277 - val_loss: 0.7509 - val_accuracy: 0.6667\n",
      "Epoch 27/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.8543 - accuracy: 0.7403 - val_loss: 0.3534 - val_accuracy: 0.8889\n",
      "Epoch 28/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.8260 - accuracy: 0.7522 - val_loss: 0.7247 - val_accuracy: 0.7778\n",
      "Epoch 29/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.8024 - accuracy: 0.7563 - val_loss: 0.8177 - val_accuracy: 0.7778\n",
      "Epoch 30/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.7873 - accuracy: 0.7650 - val_loss: 0.7036 - val_accuracy: 0.8889\n",
      "Epoch 31/40\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.7820 - accuracy: 0.7620 - val_loss: 0.5587 - val_accuracy: 0.8889\n",
      "Epoch 32/40\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 0.7582 - accuracy: 0.7675 - val_loss: 0.4869 - val_accuracy: 0.8889\n",
      "Epoch 33/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.7257 - accuracy: 0.7755 - val_loss: 0.5474 - val_accuracy: 0.7778\n",
      "Epoch 34/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.7013 - accuracy: 0.7845 - val_loss: 0.5437 - val_accuracy: 0.7778\n",
      "Epoch 35/40\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.6944 - accuracy: 0.7843 - val_loss: 0.4968 - val_accuracy: 0.7778\n",
      "Epoch 36/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.6799 - accuracy: 0.7909 - val_loss: 0.5004 - val_accuracy: 0.7778\n",
      "Epoch 37/40\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 0.6512 - accuracy: 0.7963 - val_loss: 0.6532 - val_accuracy: 0.5556\n",
      "Epoch 38/40\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.6358 - accuracy: 0.8049 - val_loss: 0.3828 - val_accuracy: 0.8889\n",
      "Epoch 39/40\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.6216 - accuracy: 0.8050 - val_loss: 0.3706 - val_accuracy: 0.8889\n",
      "Epoch 40/40\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.5911 - accuracy: 0.8156 - val_loss: 0.3941 - val_accuracy: 0.7778\n",
      "Test loss: 85.40829467773438\n",
      "Test accuracy: 88.88888955116272\n",
      "Large CNN Error: 22.22%\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "# load data(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "\n",
    "img_rows, img_cols = 28,28\n",
    "read=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/train.csv\").values\n",
    "arr=np.array\n",
    "arr = read.reshape(12524,28,28,1)\n",
    "x_train=arr\n",
    "readt=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/Test.csv\").values\n",
    "arrt=np.array\n",
    "arrt = readt.reshape(9,28,28,1)\n",
    "x_test=arrt\n",
    "y_train=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/training_label.csv\").values\n",
    "y_test=pd.read_csv(\"C:/Users/helid/PycharmProjects/GujOCR/csv/Test_label.csv\").values\n",
    "# the data, split between train and test sets\n",
    "\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train=x_train\n",
    "X_test=x_test\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define the larger model\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=150)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"C:/Users/helid/PycharmProjects/GujOCR/model/CNN88.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 30)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 15)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               48128     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 66)                3366      \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('C:/Users/helid/PycharmProjects/GujOCR/model/CNN88.h5')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted character is:૮\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dict = {'ં': 0, 'ઃ': 1, 'અ': 2, 'અં': 3, 'અઃ': 4, 'આ': 5, 'ઇ': 6,\n",
    "              'ઈ': 7, 'ઉ': 8, 'ઊ': 9, 'એ': 10, 'ઐ': 11, 'ઔ': 12, 'ક': 13,\n",
    "              'ક્ષ': 14, 'ખ': 15, 'ગ': 16, 'ઘ': 17, 'ચ': 18, 'છ': 19, 'જ': 20,\n",
    "              'જ્ઞ': 21, 'ઝ': 22, 'ટ': 23, 'ઠ': 24, 'ડ': 25, 'ઢ': 26, 'ણ': 27,\n",
    "              'ત': 28, 'થ': 29, 'દ': 30, 'ધ': 31, 'ન': 32, 'પ': 33, 'ફ': 34,\n",
    "              'બ': 35, 'ભ': 36, 'મ': 37, 'ય': 38, 'ર': 39, 'લ': 40, 'ળ': 41,\n",
    "              'વ': 42, 'શ': 43, 'ષ': 44, 'સ': 45, 'હ': 46, 'ા': 47, 'િ': 48,\n",
    "              'ી': 49, 'ુ': 50, 'ૂ': 51, 'ે': 52, 'ૈ': 53, 'ો': 54, 'ૌ': 55,\n",
    "              '૦': 56, '૧': 57, '૨': 58, '૩': 59, '૪': 60, '૫': 61, '૬': 62,\n",
    "              '૭': 63, '૮': 64, '૯': 65}\n",
    "key_list = list(dict.keys()) \n",
    "val_list = list(dict.values()) \n",
    "example = x_test[7]\n",
    "prediction = model.predict(example.reshape(1,28,28, 1))\n",
    "print(prediction)\n",
    "hard_maxed_prediction = np.zeros(prediction.shape)\n",
    "hard_maxed_prediction[0][np.argmax(prediction)] = 1\n",
    "#print (hard_maxed_prediction)\n",
    "\n",
    "plt.imshow(example.reshape(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "a = int(np.argmax(prediction))\n",
    "print('Predicted character is:'+ list(dict.keys())[list(dict.values()).index(a)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
